# PlantAI
Helping Farmers with Technology

## Our Goal
Farming is one of the most important industries that is needed for the survival of mankind. Farming provides us with food and much more. But in todayâ€™s tech era, farmers are far away from using technology for the industry. This is keeping them from achieving great potential in the industry. 

The main reason for the wide gap between tech and farmers is farmers are not well-skilled to use technology such as Artificial Intelligence, Internet, etc.  Hence with this project, we will open access to the technology for farmers with the user-friendly interface to detect the diseases of crops by clicking the image of plant leaves. That will help the farmers to know about the disease-free of cost and without hassle. 

## Problems farmers faces
### Unavailability of Technology
For diagnosing the plant diseases, expert plant doctors and researchers must visit on site. This is a very costly and inefficient method for farmers. So there is a need for the technology which will ease out the process of diagnosing the disease.
### Complex Structure Of Machine Learning Technology
Although technology is available for the above problem mentioned above, it is very complicated and impossible to access by low skilled people. This also makes the process hard.

## Our Objectives
<li>Compare the accuracy and efficiency of the Machine Learning model for the best prediction of disease.</li>
<li>Use the best model for creating a user-friendly android application with a simple interface to be used by farmers.</li>
<li>Provide user-friendly technology access to the farmers to detect plant diseases.</li>
<li>Provide relevant knowledge to the farmers about plant diseases with the help of Google API.</li>

## Research Gap We Found
As presented in the following literature review section many literature reviews talked about the accuracy and methodology of the different architecture with different types of dataset. For example some papers used single shot detection (SSD) and Convolutional neural network (CNN) architecture and found different results and accuracy.

In this exploratory study, we will we focusing on the comparative study of the architecture, model training time and accuracy of the different architecture. There is no sufficient study on the comparison of the ResNet, Xception and VGG16 according to architecture, model training time and accuracy and a brief writing about the comparison. 

Also there is no user friendly android application available which can be used by people who have little to zero understanding of the technology but the need is most.

## ML Model Architecture we used
![ml model architecture](https://user-images.githubusercontent.com/54211377/164741277-11dae845-e546-4ec6-97b1-869f97c6b5e4.png)

## Our Application Architect
![Plant Disease Classification](https://user-images.githubusercontent.com/54211377/164741412-9f77c9fd-2395-4cfa-b24a-6f0e43a02de4.png)

## References we go through
[1] J. Sun, Y. Yang, X. He, and X. Wu, "Northern Maize Leaf Blight Detection Under Complex Field Environment Based on Deep Learning," in IEEE Access, vol. 8, pp. 33679-33688, 2020, doi: 10.1109/ACCESS.2020.2973658.
https://ieeexplore.ieee.org/document/8998195

[2] M. Ahmad, M. Abdullah, H. Moon, and D. Han, "Plant Disease Detection in Imbalanced Datasets Using Efficient Convolutional Neural Networks With Stepwise Transfer Learning," in IEEE Access, vol. 9, pp. 140565-140580, 2021, doi: 10.1109/ACCESS.2021.3119655.
https://ieeexplore.ieee.org/abstract/document/9568965

[3] A. Khattak et al., "Automatic Detection of Citrus Fruit and Leaves Diseases Using Deep Neural Network Model," in IEEE Access, vol. 9, pp. 112942-112954, 2021, doi: 10.1109/ACCESS.2021.3096895.
https://ieeexplore.ieee.org/document/9481921

[4] S. Barburiceanu, S. Meza, B. Orza, R. Malutan and R. Terebes, "Convolutional Neural Networks for Texture Feature Extraction. Applications to Leaf Disease Classification in Precision Agriculture," in IEEE Access, vol. 9, pp. 160085-160103, 2021, doi: 10.1109/ACCESS.2021.3131002.
https://ieeexplore.ieee.org/document/9627678
